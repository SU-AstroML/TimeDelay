{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import correlate\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "plt.set_cmap('nipy_spectral') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TOOLS ##\n",
    "###########\n",
    "\n",
    "# Find border indices of sampling windows in data\n",
    "def pick_sampling_windows(timestamps):\n",
    "    dt = []\n",
    "    for i in xrange(1, len(timestamps)):\n",
    "        dt.append(timestamps[i]-timestamps[i-1])\n",
    "    dt_threshold = np.mean(dt)*1.\n",
    "    right_ends = np.append(np.where(dt>=dt_threshold)[0], len(timestamps)-1)\n",
    "    left_ends = np.append(0, np.where(dt>=dt_threshold)[0]+1)\n",
    "    windows = np.zeros((len(right_ends), 2))\n",
    "    for i in range(0, len(right_ends)):\n",
    "        windows[i] = (left_ends[i], right_ends[i])\n",
    "    return windows\n",
    "\n",
    "# Make a GaussianProcess model for noisy data\n",
    "def make_a_model(pairNo, x, X, y, dy, theta0=1e-3, thetaL=1e-3, thetaU=1):\n",
    "    gp = GaussianProcess(corr='squared_exponential', # If the original experiment is known to be infinitely differentiable (smooth), then one should use the squared-exponential correlation model.\n",
    "                         regr = \"quadratic\", #?\n",
    "                         theta0 = theta0,\n",
    "                         thetaL = thetaL,\n",
    "                         thetaU = thetaU,\n",
    "                         nugget = (dy / y) ** 2, #?\n",
    "                         random_start=500)\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "    gp.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis (ask for MSE as well)\n",
    "    y_pred, MSE = gp.predict(x, eval_MSE=True)\n",
    "    sigma = np.sqrt(MSE)\n",
    "    return y_pred, sigma\n",
    "\n",
    "# Make a GaussianProcess model for data without noise (It complains for TDC dataset though!)\n",
    "def make_a_perfect_model(pairNo, x, X, y):\n",
    "    gp = GaussianProcess(theta0=1e-3,\n",
    "                         thetaL=1e-3,\n",
    "                         thetaU=1,\n",
    "                         random_start=500)\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "    gp.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis (ask for MSE as well)\n",
    "    y_pred, MSE = gp.predict(x, eval_MSE=True)\n",
    "    sigma = np.sqrt(MSE)\n",
    "    return y_pred, sigma\n",
    "\n",
    "# Plot data points with error bars\n",
    "def plot_data(ax, pairNo, dt, X, y, dy, ob):\n",
    "# Plot the function, the prediction and the 95% confidence interval based on\n",
    "# the MSE\n",
    "    ax.errorbar(X.ravel() + dt, y, dy, fmt='.', markersize=10, label='Observations ' + ob)\n",
    "\n",
    "# Plot the best-fit model of data along with 95% uncertainties\n",
    "def plot_model(ax, pairNo, dt, x, y_pred, sigma, ob):\n",
    "# Plot the function, the prediction and the 95% confidence interval based on\n",
    "# the MSE\n",
    "    ax.plot(x + dt, y_pred, '-', label='Prediction ' + ob)\n",
    "    ax.fill(np.concatenate([x + dt, x[::-1] + dt]),\n",
    "        np.concatenate([y_pred - 1.9600 * sigma,\n",
    "                       (y_pred + 1.9600 * sigma)[::-1]]),\n",
    "        alpha=.5, ec='None', label='95% confidence interval ' + ob)\n",
    "\n",
    "# Cross correlate two arrays (models or data!) and return the index of the maximum correlation and the full corr array\n",
    "def cross_correlate_models(model1, model2, mode='same'):\n",
    "    corr = correlate(model1, model2, mode=mode)\n",
    "    abscorr = np.abs(corr)\n",
    "    maxcorr = np.max(abscorr)\n",
    "    return np.where(abscorr == maxcorr)[0], corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from pair1\n",
      "window 0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:26: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window 1 ...\n",
      "window 2 ...\n",
      "window 3 ...\n",
      "window 4 ...\n",
      "Window4 done!\n"
     ]
    }
   ],
   "source": [
    "# Fit GP model to each sampling window of the data separately\n",
    "N_eval = 5000\n",
    "pairNo = 1\n",
    "dt_true = -57.53\n",
    "tau = 369.9817 #l ?\n",
    "sig = 0.00672 #sigma_f ?\n",
    "print \"loading data from pair\" + str(pairNo)\n",
    "lightcurve = np.loadtxt(\"/home/saas9842/PhD/Courses/AstroML/Project/tdc1/rung3/tdc1_rung3_double_pair%d.txt\"%(pairNo),\n",
    "                        skiprows=6, dtype={\"names\":(\"time\", \"lcA\", \"errA\", \"lcB\", \"errB\"), \n",
    "                                           \"formats\":(\"f4\", \"f4\", \"f4\", \"f4\", \"f4\")})\n",
    "\n",
    "windows = pick_sampling_windows(lightcurve['time'])\n",
    "modelA = np.zeros((N_eval * len(windows), 2))\n",
    "modelB = np.zeros((N_eval * len(windows), 2))\n",
    "t_maxcorr = np.zeros((len(windows), ))\n",
    "t_eval = np.zeros((N_eval * len(windows), 1))\n",
    "\n",
    "figA, axsA = plt.subplots(len(windows)/2, len(windows)/2+1, sharex=True, sharey=True)\n",
    "axsA = axsA.flatten()\n",
    "figB, axsB = plt.subplots(len(windows)/2, len(windows)/2+1, sharex=True, sharey=True)\n",
    "axsB = axsB.flatten()\n",
    "\n",
    "for i, window in enumerate(windows):\n",
    "    print \"window \" + str(i) + \" ...\"\n",
    "    \n",
    "    data = lightcurve[window[0]:window[1]]\n",
    "    t_eval[N_eval*i:N_eval*(i+1)] = np.atleast_2d(np.linspace(np.min(data['time']), np.max(data['time']), N_eval)).T\n",
    "    \n",
    "# find the best-fit model for LC A\n",
    "    XA = data['time'].T\n",
    "    XA = XA.reshape((len(XA), 1))\n",
    "    fA = (data['lcA'] - np.mean(data['lcA'])) / np.std(data['lcA'])\n",
    "    dfA = (data['errA'] - np.mean(data['errA'])) / np.std(data['errA'])\n",
    "    modelA[N_eval*i:N_eval*(i+1), 0], modelA[N_eval*i:N_eval*(i+1), 1] = make_a_model(pairNo, \n",
    "                                                                                      t_eval[N_eval*i:N_eval*(i+1)], \n",
    "                                                                                      XA, fA, dfA,\n",
    "                                                                                     theta0=sig,\n",
    "                                                                                     thetaL=tau,\n",
    "                                                                                     thetaU=tau) # image A\n",
    "\n",
    "# find the best-fit model for LC B\n",
    "    XB = data['time'].T\n",
    "    XB = XB.reshape((len(XB), 1))\n",
    "    fB = (data['lcB'] - np.mean(data['lcB'])) / np.std(data['lcB'])\n",
    "    dfB = (data['errB'] - np.mean(data['errB'])) / np.std(data['errB'])\n",
    "    modelB[N_eval*i:N_eval*(i+1), 0], modelB[N_eval*i:N_eval*(i+1), 1] = make_a_model(pairNo, \n",
    "                                                                                      t_eval[N_eval*i:N_eval*(i+1)], \n",
    "                                                                                      XB, fB, dfB,\n",
    "                                                                                     theta0=sig,\n",
    "                                                                                     thetaL=tau,\n",
    "                                                                                     thetaU=tau) # image B\n",
    "\n",
    "    # Cross correlate the two models\n",
    "    ind_maxcorr, corr = cross_correlate_models(modelA[N_eval*i:N_eval*(i+1), 0],\n",
    "                                               modelB[N_eval*i:N_eval*(i+1), 0])\n",
    "\n",
    "    maxcorr = t_eval[ind_maxcorr]\n",
    "    t_maxcorr[i] = maxcorr[0][0]\n",
    "    \n",
    "    \n",
    "###  plot_model(pairNo, dt, x, y_pred, sigma, ob)   \n",
    "\n",
    "    plot_data(axsA[i], pairNo, 0, XA, fA, dfA, \"A\") #A\n",
    "    plot_model(axsA[i], pairNo, 0, \n",
    "               t_eval[N_eval*i:N_eval*(i+1)], \n",
    "               modelA[N_eval*i:N_eval*(i+1), 0], \n",
    "               modelA[N_eval*i:N_eval*(i+1), 1],\n",
    "               \"A \") #A\n",
    "    \n",
    "    plot_data(axsB[i], pairNo, 0, XB, fB, dfB, \"B\") #B\n",
    "    plot_model(axsB[i], pairNo, 0, \n",
    "               t_eval[N_eval*i:N_eval*(i+1)], \n",
    "               modelB[N_eval*i:N_eval*(i+1), 0], \n",
    "               modelB[N_eval*i:N_eval*(i+1), 1],\n",
    "               \"B \") #B\n",
    "    \n",
    "#    plt.plot(t_eval[N_eval*i:N_eval*(i+1)], (corr - np.mean(corr)) / np.std(corr),\n",
    "#             '-y', linewidth=3, label=\"Cross correlation\")\n",
    "#    plt.xlabel('t [days]')\n",
    "#    plt.ylabel('normalized flux [arbitrary]')\n",
    "#    plt.title(\"Window: \" + str(i) + \" - max. cross correlation at t=\" + str(t_maxcorr[i]))\n",
    "#    plt.title('PairNo: ' + str(pairNo) +\n",
    "#              ' - true time delay: ' + str(dt_true) +\n",
    "#              ' - maximum correlation at: ' + str(t_maxcorr))\n",
    "    \n",
    "#plt.legend()\n",
    "#    plt.savefig(\"window\" + str(i) + \".png\")\n",
    "plt.show()\n",
    "print \"Window\" + str(i) + \" done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.7499370147 66.2237245632 22.4313097981\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t_maxcorr = np.array(t_maxcorr)\n",
    "print np.mean(t_maxcorr), np.median(t_maxcorr), np.std(t_maxcorr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 9 done!\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Process\n",
    "#dt_trues = [-57.53, -33.49, -108.85, 71.03, -33.82, -62.04, -61.6, -73.6, 41.9, 104.22]\n",
    "periods = []\n",
    "dt_preds = []\n",
    "dt_trues = [41.9]#, 104.22]\n",
    "for pairNo, dt_true in zip(range(9, 10), dt_trues):\n",
    "    lightcurve = np.loadtxt(\"/home/saas9842/PhD/Courses/AstroML/Project/tdc1/rung3/tdc1_rung3_double_pair%d.txt\"%(pairNo),\n",
    "                            skiprows=6, dtype={\"names\":(\"time\", \"lcA\", \"errA\", \"lcB\", \"errB\"), \n",
    "                                               \"formats\":(\"f4\", \"f4\", \"f4\", \"f4\", \"f4\")})\n",
    "    x = np.atleast_2d(np.linspace(0, np.max(lightcurve['time']), 5000)).T\n",
    "    XA = lightcurve['time'].T\n",
    "    XA = XA.reshape((len(XA), 1))\n",
    "    yA = (lightcurve['lcA'] - np.mean(lightcurve['lcA'])) / np.std(lightcurve['lcA'])\n",
    "    dyA = (lightcurve['errA'] - np.mean(lightcurve['errA'])) / np.std(lightcurve['errA'])\n",
    "    y_predA, sigmaA = make_a_model(pairNo, x, XA, yA, dyA, theta0=sig, thetaL=tau, thetaU=tau) #A\n",
    "\n",
    "    \n",
    "    XB = (lightcurve['time']).T\n",
    "    XB = XB.reshape((len(XB), 1))\n",
    "    yB = (lightcurve['lcB'] - np.mean(lightcurve['lcB'])) / np.std(lightcurve['lcB'])\n",
    "    dyB = (lightcurve['errB'] - np.mean(lightcurve['errB'])) / np.std(lightcurve['errB'])\n",
    "    y_predB, sigmaB = make_a_model(pairNo, x, XB, yB, dyB, theta0=sig, thetaL=tau, thetaU=tau) #B\n",
    "    \n",
    "\n",
    "# Cross correlate the two models\n",
    "    ind_maxcorr, corr = cross_correlate_models(y_predA, y_predB)\n",
    "    t_maxcorr = x[ind_maxcorr]\n",
    "    t_maxcorr = t_maxcorr[0][0]\n",
    "\n",
    "# Autcorelate each of the models for an estimate of their periods individually\n",
    "    ind_max_acfA, corrA = cross_correlate_models(y_predA, y_predA)\n",
    "    t_max_acfA = x[ind_max_acfA]\n",
    "    t_max_acfA = t_max_acfA[0][0]\n",
    "\n",
    "    ind_max_acfB, corrB = cross_correlate_models(y_predB, y_predB)\n",
    "    t_max_acfB = x[ind_max_acfB]\n",
    "    t_max_acfB = t_max_acfB[0][0]\n",
    "\n",
    "    periods.append(t_max_acfB)\n",
    "    dt_preds.append(t_maxcorr)\n",
    "    \n",
    "    print \"Pair \" + str(pairNo) + \" done!\"\n",
    "    \n",
    "    # Plot everything\n",
    "    plt.figure()\n",
    "\n",
    "    plot_data(pairNo, 0, XA, yA, dyA, \"A\") # A\n",
    "    plot_model(pairNo, 0, x, y_predA, sigmaA,\"A \") # A\n",
    "    \n",
    "    plot_data(pairNo, 0, XB, yB, dyB, \"B\") # B\n",
    "    plot_model(pairNo, 0, x, y_predB, sigmaB,\"B \") # B\n",
    "    \n",
    "    plt.plot(x, (corr - np.mean(corr)) / np.std(corr),\n",
    "             '-y', linewidth=3, label=\"Cross correlation\")\n",
    "    plt.xlabel('t [days]')\n",
    "    plt.ylabel('normalized flux [arbitrary]')\n",
    "    plt.title('PairNo: ' + str(pairNo) +\n",
    "              ' - true time delay: ' + str(dt_true) +\n",
    "              ' - maximum correlation at: ' + str(t_maxcorr))\n",
    "    \n",
    "#    plt.legend().draggable()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Investigate the correlations for the outputs of Gaussian Process modeling; period, maximum correlation, true time delay\n",
    "periods = np.array(periods)\n",
    "dt_trues = np.array(dt_trues)\n",
    "dt_preds = np.array(dt_preds)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(dt_trues, periods, marker='o', c=periods, edgecolor='None', s=150)\n",
    "plt.plot(dt_trues, dt_trues, linewidth=3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(dt_trues, periods, marker='o', c=dt_preds, edgecolor='None', s=150)\n",
    "plt.plot(dt_trues, dt_trues, linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## GPR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.22 42.3452325231\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
